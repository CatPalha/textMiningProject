{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "from unidecode import unidecode\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_corpus(filename):\n",
    "    corpus = Path(filename).read_text(encoding=\"utf8\")\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_corpora(filelist,author):\n",
    "    files = []\n",
    "    for file in filelist:\n",
    "        location = \"Corpora/train/\"+file\n",
    "        corpus = load_corpus(location)\n",
    "        files.append(corpus)\n",
    "    df = pd.DataFrame(files, columns=['Text'])\n",
    "    df['Author'] = pd.Series([author for x in range(len(df.index))], index=df.index)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_almada = [\n",
    "    'AlmadaNegreiros/pg22615.txt',\n",
    "    'AlmadaNegreiros/pg22730.txt',\n",
    "    'AlmadaNegreiros/pg22801.txt',\n",
    "    'AlmadaNegreiros/pg22802.txt',\n",
    "    'AlmadaNegreiros/pg22969.txt',\n",
    "    'AlmadaNegreiros/pg23133.txt',\n",
    "    'AlmadaNegreiros/pg23620.txt',\n",
    "    'AlmadaNegreiros/pg23879.txt',\n",
    "    'AlmadaNegreiros/pg23961.txt'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpora_almada = load_corpora(train_set_almada, 'Almada Negreiros')\n",
    "corpora_almada.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_camilo = [\n",
    "    'CamiloCasteloBranco/24691-0.txt',\n",
    "    'CamiloCasteloBranco/34756-0.txt',\n",
    "    'CamiloCasteloBranco/pg16425.txt',\n",
    "    'CamiloCasteloBranco/pg17927.txt',\n",
    "    'CamiloCasteloBranco/pg19375.txt',\n",
    "    'CamiloCasteloBranco/pg21406.txt',\n",
    "    'CamiloCasteloBranco/pg23203.txt',\n",
    "    'CamiloCasteloBranco/pg23345.txt',\n",
    "    'CamiloCasteloBranco/pg23346.txt',\n",
    "    'CamiloCasteloBranco/pg24339.txt',\n",
    "    'CamiloCasteloBranco/pg25844.txt',\n",
    "    'CamiloCasteloBranco/pg26017.txt',\n",
    "    'CamiloCasteloBranco/pg26103.txt',\n",
    "    'CamiloCasteloBranco/pg26110.txt',\n",
    "    'CamiloCasteloBranco/pg26988.txt',\n",
    "    'CamiloCasteloBranco/pg27364.txt',\n",
    "    'CamiloCasteloBranco/pg27541.txt',\n",
    "    'CamiloCasteloBranco/pg28310.txt',\n",
    "    'CamiloCasteloBranco/pg31694.txt',\n",
    "    'CamiloCasteloBranco/pg33788.txt',\n",
    "]\n",
    "\n",
    "corpora_camilo = load_corpora(train_set_camilo, 'Camilo Castelo Branco')\n",
    "corpora_camilo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_eca = [\n",
    "    'EcaDeQueiros/pg18220.txt',\n",
    "    'EcaDeQueiros/pg25641.txt',\n",
    "    'EcaDeQueiros/pg27637.txt',\n",
    "    'EcaDeQueiros/pg31347.txt',\n",
    "    'EcaDeQueiros/pg40409.txt'\n",
    "]\n",
    "\n",
    "corpora_eca = load_corpora(train_set_eca, 'Eca de Queiros')\n",
    "corpora_eca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_rodrigues_santos = [\n",
    "    'JoseRodriguesSantos/A Filha Do Capitao - Jose Rodrigues dos Santos.txt',\n",
    "    'JoseRodriguesSantos/A Formula De Deus - Jose Rodrigues dos Santos.txt',\n",
    "    'JoseRodriguesSantos/A Mao do Diabo - Jose Rodrigues dos Santos.txt',\n",
    "    'JoseRodriguesSantos/A Vida Num Sopro - Jose Rodrigues dos Santos.txt',\n",
    "    'JoseRodriguesSantos/Furia Divina - Jose Rodrigues dos Santos.txt',\n",
    "    'JoseRodriguesSantos/O Anjo Branco - Jose Rodrigues dos Santos.txt',\n",
    "    'JoseRodriguesSantos/O Setimo Selo - Jose Rodrigues dos Santos.txt',\n",
    "    'JoseRodriguesSantos/O ultimo Segredo - Jose Rodrigues dos Santos.txt'\n",
    "]\n",
    "\n",
    "corpora_rodrigues_santos = load_corpora(train_set_rodrigues_santos, 'Jose Rodrigues dos Santos')\n",
    "corpora_rodrigues_santos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 2)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_saramago = [\n",
    "    'JoseSaramago/A Caverna - Jose Saramago.txt',\n",
    "    'JoseSaramago/As Intermitencias da Morte - Jose Saramago.txt',\n",
    "    'JoseSaramago/Caim - Jose Saramago.txt',\n",
    "    'JoseSaramago/Claraboia - Jose Saramago.txt',\n",
    "    'JoseSaramago/Ensaio Sobre a Cegueira - Jose Saramago.txt',\n",
    "    'JoseSaramago/Historia Do Cerco De Lisboa - Jose Saramago.txt',\n",
    "    'JoseSaramago/Memorial Do Convento - Jose Saramago.txt',\n",
    "    'JoseSaramago/O Ano Da Morte De Ricardo Reis - Jose Saramago.txt',\n",
    "    'JoseSaramago/O Conto Da Ilha Desconhecida - Jose Saramago.txt',\n",
    "    'JoseSaramago/O Homem Duplicado - Jose Saramago.txt',\n",
    "    'JoseSaramago/Terra Do Pecado - Jose Saramago.txt',\n",
    "    'JoseSaramago/Viagem Do Elefante - Jose Saramago.txt'\n",
    "]\n",
    "\n",
    "corpora_saramago = load_corpora(train_set_saramago, 'Jose Saramago')\n",
    "corpora_saramago.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 2)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_luisa = [\n",
    "    'LuisaMarquesSilva/ABelaHistoria.txt',\n",
    "    'LuisaMarquesSilva/acabouSe.txt',\n",
    "    'LuisaMarquesSilva/Botão.txt',\n",
    "    'LuisaMarquesSilva/controlz.txt',\n",
    "    'LuisaMarquesSilva/emedo.txt',\n",
    "    'LuisaMarquesSilva/Lisboa2050.txt',\n",
    "    'LuisaMarquesSilva/passeioInferno.txt',\n",
    "    'LuisaMarquesSilva/rapsodiasemdo.txt',\n",
    "    'LuisaMarquesSilva/UltimaHistoria.txt'\n",
    "]\n",
    "\n",
    "corpora_luisa = load_corpora(train_set_luisa, 'Luisa Marques Silva')\n",
    "corpora_luisa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63, 2)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpora = pd.concat([corpora_almada, corpora_camilo, corpora_eca, corpora_rodrigues_santos, corpora_saramago, corpora_luisa]).reset_index(drop = True)\n",
    "corpora.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom unidecode import unidecode\\n\\ncorpora['Text'] = corpora['Text'].apply(lambda text: unidecode(text))\\n\\ncorpora\\n\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from unidecode import unidecode\n",
    "\n",
    "corpora['Text'] = corpora['Text'].apply(lambda text: unidecode(text))\n",
    "\n",
    "corpora\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nchar = ''\\n\\nfor text in corpora['Text']:\\n    characters = list(set(text))\\n    for c in characters:\\n        char += c\\n    #print(list(set(text)))\\n    \\nprint(list(set(char)))\\n\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "char = ''\n",
    "\n",
    "for text in corpora['Text']:\n",
    "    characters = list(set(text))\n",
    "    for c in characters:\n",
    "        char += c\n",
    "    #print(list(set(text)))\n",
    "    \n",
    "print(list(set(char)))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nrep = {\\'\\n\\':\\' \\',\\n       \\'#\\':\\'\\',\\n       \\'+\\':\\'\\',\\n       \\'-\\':\\' \\',\\n       \\'_\\':\\'\\',\\n       \\'<\\':\\'\\',\\n       \\'>\\':\\'\\',\\n       \\'=\\':\\'\\',\\n       \\'*\\':\\'\\',\\n       \\'\\\\\\':\\'\\',\\n       \\'|\\':\\'\\',\\n       \\'~\\':\\'\\',\\n       \\'[\\':\\'\\',\\n       \\']\\':\\'\\',\\n       \"\\'\":\\' \\',\\n       \\'\"\\':\\'\\',\\n       \\'  \\':\\' \\'\\n      }\\n\\nfor i,j in rep.items():\\n    corpora[\\'Text\\'] = corpora[\\'Text\\'].apply(lambda text: text.replace(i,j))\\n\\n#print(corpora.loc[0,\\'Text\\'])\\n\\ncorpora\\n'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "rep = {'\\n':' ',\n",
    "       '#':'',\n",
    "       '+':'',\n",
    "       '-':' ',\n",
    "       '_':'',\n",
    "       '<':'',\n",
    "       '>':'',\n",
    "       '=':'',\n",
    "       '*':'',\n",
    "       '\\\\':'',\n",
    "       '|':'',\n",
    "       '~':'',\n",
    "       '[':'',\n",
    "       ']':'',\n",
    "       \"'\":' ',\n",
    "       '\"':'',\n",
    "       '  ':' '\n",
    "      }\n",
    "\n",
    "for i,j in rep.items():\n",
    "    corpora['Text'] = corpora['Text'].apply(lambda text: text.replace(i,j))\n",
    "\n",
    "#print(corpora.loc[0,'Text'])\n",
    "\n",
    "corpora\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(corpora['Text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(dataframe):\n",
    "    processed_corpus = []\n",
    "    \n",
    "    stop_words_pt = set(stopwords.words(\"portuguese\"))\n",
    "    stop_words_en = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    for i in tqdm(range(len(dataframe))):\n",
    "        text = dataframe['Text'][i]\n",
    "        \n",
    "        #Remove accents\n",
    "        text = unidecode(text)\n",
    "        \n",
    "        #Remove specific punctuations\n",
    "        #rep = {'\\n':' ','#':'','+':'','-':' ','_':'','<':'','>':'','=':'','*':'','\\\\':'','|':'','~':'','[':'',']':'',\n",
    "               #\"'\":' ','\"':'','  ':' '}\n",
    "        #remove punctuation \n",
    "        text = re.sub('[^a-zA-Z]', ' ', text) \n",
    "\n",
    "        #for i,j in rep.items():\n",
    "            #text = text.replace(i,j)\n",
    "        \n",
    "        #Convert to lowercase\n",
    "        text = text.lower()\n",
    "\n",
    "        #remove tags\n",
    "        text = BeautifulSoup(text).get_text()\n",
    "        \n",
    "        # Convert to list from string\n",
    "        text = text.split()\n",
    "\n",
    "        #Lemmatisation\n",
    "        lem = WordNetLemmatizer()\n",
    "        text = [lem.lemmatize(word) for word in text if not word in stop_words_pt]\n",
    "        #print(text)\n",
    "        #text_2 = [lem.lemmatize(word) for word in text if not word in stop_words_pt] \n",
    "        text = \" \".join(text)\n",
    "        \n",
    "        #text_2 = [lem.lemmatize(word) for word in text if not word in stop_words_pt]\n",
    "        #text = \" \".join(text_2)\n",
    "        #print(text)\n",
    "        processed_corpus.append(text)\n",
    "    return processed_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d706ccd43794d7083ebf7b3d1380378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=63), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_corpora = preprocessing(corpora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Author</th>\n",
       "      <th>Clean Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Title: A Scena do Odio\\n\\nAuthor: José de Alma...</td>\n",
       "      <td>Almada Negreiros</td>\n",
       "      <td>title scena odio author jose almada negreiros ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Title: O Jardim da Pierrette\\n\\nAuthor: José d...</td>\n",
       "      <td>Almada Negreiros</td>\n",
       "      <td>title jardim pierrette author jose almada negr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>\\n\\nTitle: A Invenção do Dia Claro\\n\\nAuthor: ...</td>\n",
       "      <td>Almada Negreiros</td>\n",
       "      <td>title invencao dia claro author jose almada ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\\nTitle: Litoral\\n       A Amadeo de Souza Car...</td>\n",
       "      <td>Almada Negreiros</td>\n",
       "      <td>title litoral amadeo souza cardozo author jose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>\\n\\n\\nEXPOSIÇÃO\\n\\n+amadeo\\nde souza\\ncardoso+...</td>\n",
       "      <td>Almada Negreiros</td>\n",
       "      <td>exposicao amadeo souza cardoso liga naval lisb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>Título\\ne-medo\\n\\nAutora (inspiradíssima)\\nLuí...</td>\n",
       "      <td>Luisa Marques Silva</td>\n",
       "      <td>titulo medo autora inspiradissima luisa marque...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>LISBOA 2050\\nLisboa, ano de 2050. Um Agosto tã...</td>\n",
       "      <td>Luisa Marques Silva</td>\n",
       "      <td>lisboa lisboa ano agosto tao gelado ha vinte a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>Título\\nUm passeio pelo inferno\\n\\nAutora\\nLuí...</td>\n",
       "      <td>Luisa Marques Silva</td>\n",
       "      <td>titulo passeio inferno autora luisa marque sil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>Título\\nRapsódia sem dó (maior)\\n\\nAutora\\nLuí...</td>\n",
       "      <td>Luisa Marques Silva</td>\n",
       "      <td>titulo rapsodia maior autora luisa marque silv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>Título\\nA última história\\n\\nAutora (próximo N...</td>\n",
       "      <td>Luisa Marques Silva</td>\n",
       "      <td>titulo ultima historia autora proximo nobel lu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text               Author  \\\n",
       "0   Title: A Scena do Odio\\n\\nAuthor: José de Alma...     Almada Negreiros   \n",
       "1   Title: O Jardim da Pierrette\\n\\nAuthor: José d...     Almada Negreiros   \n",
       "2   \\n\\nTitle: A Invenção do Dia Claro\\n\\nAuthor: ...     Almada Negreiros   \n",
       "3   \\nTitle: Litoral\\n       A Amadeo de Souza Car...     Almada Negreiros   \n",
       "4   \\n\\n\\nEXPOSIÇÃO\\n\\n+amadeo\\nde souza\\ncardoso+...     Almada Negreiros   \n",
       "..                                                ...                  ...   \n",
       "58  Título\\ne-medo\\n\\nAutora (inspiradíssima)\\nLuí...  Luisa Marques Silva   \n",
       "59  LISBOA 2050\\nLisboa, ano de 2050. Um Agosto tã...  Luisa Marques Silva   \n",
       "60  Título\\nUm passeio pelo inferno\\n\\nAutora\\nLuí...  Luisa Marques Silva   \n",
       "61  Título\\nRapsódia sem dó (maior)\\n\\nAutora\\nLuí...  Luisa Marques Silva   \n",
       "62  Título\\nA última história\\n\\nAutora (próximo N...  Luisa Marques Silva   \n",
       "\n",
       "                                           Clean Text  \n",
       "0   title scena odio author jose almada negreiros ...  \n",
       "1   title jardim pierrette author jose almada negr...  \n",
       "2   title invencao dia claro author jose almada ne...  \n",
       "3   title litoral amadeo souza cardozo author jose...  \n",
       "4   exposicao amadeo souza cardoso liga naval lisb...  \n",
       "..                                                ...  \n",
       "58  titulo medo autora inspiradissima luisa marque...  \n",
       "59  lisboa lisboa ano agosto tao gelado ha vinte a...  \n",
       "60  titulo passeio inferno autora luisa marque sil...  \n",
       "61  titulo rapsodia maior autora luisa marque silv...  \n",
       "62  titulo ultima historia autora proximo nobel lu...  \n",
       "\n",
       "[63 rows x 3 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpora['Clean Text'] = pd.Series(cleaned_corpora, index = corpora.index)\n",
    "corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Author</th>\n",
       "      <th>Clean Text</th>\n",
       "      <th>word_count_text</th>\n",
       "      <th>word_count_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Title: A Scena do Odio\\n\\nAuthor: José de Alma...</td>\n",
       "      <td>Almada Negreiros</td>\n",
       "      <td>title scena odio author jose almada negreiros ...</td>\n",
       "      <td>1456</td>\n",
       "      <td>1139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Title: O Jardim da Pierrette\\n\\nAuthor: José d...</td>\n",
       "      <td>Almada Negreiros</td>\n",
       "      <td>title jardim pierrette author jose almada negr...</td>\n",
       "      <td>280</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>\\n\\nTitle: A Invenção do Dia Claro\\n\\nAuthor: ...</td>\n",
       "      <td>Almada Negreiros</td>\n",
       "      <td>title invencao dia claro author jose almada ne...</td>\n",
       "      <td>6212</td>\n",
       "      <td>3439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\\nTitle: Litoral\\n       A Amadeo de Souza Car...</td>\n",
       "      <td>Almada Negreiros</td>\n",
       "      <td>title litoral amadeo souza cardozo author jose...</td>\n",
       "      <td>1225</td>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>\\n\\n\\nEXPOSIÇÃO\\n\\n+amadeo\\nde souza\\ncardoso+...</td>\n",
       "      <td>Almada Negreiros</td>\n",
       "      <td>exposicao amadeo souza cardoso liga naval lisb...</td>\n",
       "      <td>521</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text            Author  \\\n",
       "0  Title: A Scena do Odio\\n\\nAuthor: José de Alma...  Almada Negreiros   \n",
       "1  Title: O Jardim da Pierrette\\n\\nAuthor: José d...  Almada Negreiros   \n",
       "2  \\n\\nTitle: A Invenção do Dia Claro\\n\\nAuthor: ...  Almada Negreiros   \n",
       "3  \\nTitle: Litoral\\n       A Amadeo de Souza Car...  Almada Negreiros   \n",
       "4  \\n\\n\\nEXPOSIÇÃO\\n\\n+amadeo\\nde souza\\ncardoso+...  Almada Negreiros   \n",
       "\n",
       "                                          Clean Text  word_count_text  \\\n",
       "0  title scena odio author jose almada negreiros ...             1456   \n",
       "1  title jardim pierrette author jose almada negr...              280   \n",
       "2  title invencao dia claro author jose almada ne...             6212   \n",
       "3  title litoral amadeo souza cardozo author jose...             1225   \n",
       "4  exposicao amadeo souza cardoso liga naval lisb...              521   \n",
       "\n",
       "   word_count_clean  \n",
       "0              1139  \n",
       "1               203  \n",
       "2              3439  \n",
       "3               476  \n",
       "4               354  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count = corpora['Clean Text'].apply(lambda x: len(str(x).split(\" \")))\n",
    "word_count_2 = corpora['Text'].apply(lambda x: len(str(x).split(\" \")))\n",
    "corpora['word_count_text'] = word_count_2\n",
    "corpora['word_count_clean'] = word_count\n",
    "corpora.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count_text</th>\n",
       "      <th>word_count_clean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Almada Negreiros</td>\n",
       "      <td>43610</td>\n",
       "      <td>27887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Camilo Castelo Branco</td>\n",
       "      <td>749872</td>\n",
       "      <td>454886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Eca de Queiros</td>\n",
       "      <td>438367</td>\n",
       "      <td>272083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Jose Rodrigues dos Santos</td>\n",
       "      <td>1131971</td>\n",
       "      <td>668358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Jose Saramago</td>\n",
       "      <td>1006571</td>\n",
       "      <td>583250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Luisa Marques Silva</td>\n",
       "      <td>41214</td>\n",
       "      <td>24114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           word_count_text  word_count_clean\n",
       "Author                                                      \n",
       "Almada Negreiros                     43610             27887\n",
       "Camilo Castelo Branco               749872            454886\n",
       "Eca de Queiros                      438367            272083\n",
       "Jose Rodrigues dos Santos          1131971            668358\n",
       "Jose Saramago                      1006571            583250\n",
       "Luisa Marques Silva                  41214             24114"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpora.groupby(['Author']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count        63.000000\n",
       "mean      32231.396825\n",
       "std       31577.716825\n",
       "min         203.000000\n",
       "25%        3599.500000\n",
       "50%       28211.000000\n",
       "75%       45676.500000\n",
       "max      131684.000000\n",
       "Name: word_count_clean, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpora.word_count_clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = ' '.join(corpora['Clean Text']).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count all words\n",
    "freq = pd.Series(all_words).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nao       52050\n",
       "d         12481\n",
       "ja         9952\n",
       "disse      7494\n",
       "la         7176\n",
       "ser        7060\n",
       "ainda      6639\n",
       "ha         5941\n",
       "bem        5716\n",
       "dia        5661\n",
       "onde       5642\n",
       "mao        5556\n",
       "so         5418\n",
       "ate        5225\n",
       "sobre      5090\n",
       "porque     5011\n",
       "assim      4912\n",
       "olhos      4908\n",
       "n          4875\n",
       "toda       4868\n",
       "tempo      4857\n",
       "aqui       4824\n",
       "tudo       4785\n",
       "agora      4730\n",
       "homem      4713\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Maren\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the top 30 most frequent words count the number of stopwords. What's the percentage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words(\"portuguese\"))\n",
    "count = 0\n",
    "for word in freq.index[:30]:\n",
    "    if word in stopwords:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'set' object has no attribute 'words'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-5593978c54cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcleaned_corpora_english\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpora\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-56-c1b3281d9a32>\u001b[0m in \u001b[0;36mpreprocessing\u001b[1;34m(dataframe)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprocessed_corpus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mstop_words_pt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"portuguese\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mstop_words_en\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"english\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'set' object has no attribute 'words'"
     ]
    }
   ],
   "source": [
    "cleaned_corpora_english = preprocessing(corpora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(\n",
    "    max_df=0.8,\n",
    "    stop_words=\"portuguese\", \n",
    "    max_features=10000, \n",
    "    ngram_range=(1,3) # all inclusive from {1,2,3}, if only bigrams use (2,2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#snowball_stemmer = SnowballStemmer('portuguese', 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not a built-in stop list: portuguese",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-5205f4604951>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleaned_corpora\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1056\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1057\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[1;32m-> 1058\u001b[1;33m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m    960\u001b[0m             \u001b[0mvocabulary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_factory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__len__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 962\u001b[1;33m         \u001b[0manalyze\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_analyzer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    963\u001b[0m         \u001b[0mj_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m         \u001b[0mindptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mbuild_analyzer\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manalyzer\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'word'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 347\u001b[1;33m             \u001b[0mstop_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_stop_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    348\u001b[0m             \u001b[0mtokenize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_tokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m             self._check_stop_words_consistency(stop_words, preprocess,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mget_stop_words\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_stop_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[1;34m\"\"\"Build or fetch the effective stop words list\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_check_stop_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_stop_words_consistency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_check_stop_list\u001b[1;34m(stop)\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mENGLISH_STOP_WORDS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"not a built-in stop list: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mstop\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not a built-in stop list: portuguese"
     ]
    }
   ],
   "source": [
    "X = cv.fit_transform(cleaned_corpora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_corpora_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(cv.vocabulary_keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "def number_token(text):\n",
    "    \"\"\"\n",
    "    Function that receives a string of text and returns the string with \n",
    "    the number formats within it substituted by the token #COST\n",
    "    \"\"\"\n",
    "    text = re.sub('(\\d+|\\d+.\\d+)(| )(\\$)', '#COST', text)\n",
    "    tokenized_cost = re.sub('(\\$)(| )(\\d+.\\d+.\\d+)', \"#COST\", text)\n",
    "    \n",
    "    return tokenized_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
