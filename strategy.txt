1. Normalization
  -Tokenize dates and numbers - probably not useful
  -Replace all accents - done
2. Lowercasing - done
3. Tokenization
  -Compounds (later) - we have n-grams but still not sure what to do about it
  -Punctuation - count it maybe? Remove it?
4. Remove Stop-Words - done
5. Stemming and lemmatisation - we're using lemmatization but we should see later if it performs better with stemming

6. POS flitering (later)

Baseline: knn

Evaluation:
-Precision
-Recall
-Accuracy
-F-measure
-...

Ideas:
TF-IDF to identify words that are specific to a certain author?? - useful for stop words
Careful with imbalanced learning